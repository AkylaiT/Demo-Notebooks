{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Web-content\" data-toc-modified-id=\"Web-content-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Web content</a></span><ul class=\"toc-item\"><li><span><a href=\"#HTML-+-CSS\" data-toc-modified-id=\"HTML-+-CSS-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>HTML + CSS</a></span></li></ul></li><li><span><a href=\"#Requests-Library\" data-toc-modified-id=\"Requests-Library-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Requests Library</a></span></li><li><span><a href=\"#Get-our-first-useful-data.\" data-toc-modified-id=\"Get-our-first-useful-data.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Get our first useful data.</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Web content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the biggest source if data? Obviously Internet. The biggest source of information we can't live without.  \n",
    "Just imagine yourself the day when we lose Internet. What will you do? Nothing, right? No more Netflix, no more Wikipedia, no more Spotify. Most of the entertainment is web based nowadays. At the same time, all of the bank transactions are done via Internet. So, you won't be able to pay via your phone (NFC technology), via your Contactless card, or even simple card. The only way to pay - via cash. That sucks.\n",
    "\n",
    "For data people internet is not just a place for entertainment, but the source of data. For some companies Internet is the only mean of existance. They use data from web, aggregate it and sell it back. Smart dudes :D\n",
    "\n",
    "Web scraping tools are designed to extract data from websites. These tools are useful for those who wants to get data from the Internet. Web scraping is a technology that allows you to automize data collection: instead of opening windows and copy pasting the content you have to write a short script and collect any volume of information. These tools allow you to manually or automatically retrieve new or updated data and save it for later use. For example, using web scraping tools you can extract information about products and prices from online stores.\n",
    "\n",
    "Possible scenarios for using web scraping tools:\n",
    "\n",
    "* Data collection for marketing research\n",
    "* Contact information extraction (email addresses, phone numbers, etc.) from different sites\n",
    "* StackOverFlow solution retrieval (or other similar resource) for offline access\n",
    "* Job offer real-time collection\n",
    "* Price tracking\n",
    "\n",
    "Depending on complexity and time expenses web pages can be split by 2 main groups:\n",
    "\n",
    "* API based websites\n",
    "* HTML based websites\n",
    "\n",
    "For those problems you need completely different approach. For API based websites solution can be found and data can be collected within several minutes, while for HTML based websites it usually takes few hours to collect all nessesary information.\n",
    "\n",
    "As a real-life example you can find [here](https://github.com/andreybavt/apart_facile).\n",
    "\n",
    "How do we get this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## HTML + CSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What can we see on the website?\n",
    "\n",
    "1. HTML code. Defines the structure of webpage. Simply it is a placeholder for every element on the page, such as links, images, text, videoplayers, etc. Has a very specific structured syntax.\n",
    "2. Image. \n",
    "3. Audio. Not popular type of objects. Usually cashed to your laptop when you load the page, therefore easily accessible.\n",
    "4. Video. Popular nowadays. Mostly streamed to the webpage, therefore uploaded as encoded objects in chunks - short pieces of video (therefore, difficult to download).\n",
    "5. CSS code. Defines the styling of objects on webpage. Color, font, size, etc. are defined with CSS.\n",
    "6. JavaScript code. Operates with dynamic objects on the webpage, such as ads or streamed data. Usually connects webpage with database.\n",
    "7. Fonts. Just like an audio, cashed to your laptop. \n",
    "8. Application data. Whenever you see pdf files being displayed on the page - it is Adobe/Fine/etc. reader that is connected to the webpage to display the file.\n",
    "\n",
    "The list above is not full, but it describes most of objects you can see on the page. What kind of information we usually care about? Text! Text is easy to read and process. Much easier than anything else. So, our main point of interest is HTML and CSS code.\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/2f5fe0786f073bf23b62ada3f864327642516dc9/68747470733a2f2f73332d65752d776573742d312e616d617a6f6e6177732e636f6d2f69682d6d6174657269616c732f75706c6f6164732f646174612d7374617469632f696d616765732f68746d6c2d6578616d706c652e706e67\">\n",
    "\n",
    "Here you can see [this webpage]('https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/the-html5-breakfast-site.html').\n",
    "\n",
    "What does this page looks like?\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>The HTML5 Breakfast Site</title>\n",
    "        <meta charset=\"utf-8\"/>\n",
    "        <style>\n",
    "            body {\n",
    "                background-color: limegreen;\n",
    "                margin: 40px;\n",
    "                } \n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div id=\"container\">\n",
    "            <nav id=\"topnav\">\n",
    "                <a href=\"https://www.ironhack.com\" target=\"_blank\">HOME</a> \n",
    "                <a href=\"https://www.ironhack.com/en/team\" target=\"_blank\">ABOUT US</a> \n",
    "                <a href=\"https://www.ironhack.com/en/contact\" target=\"_blank\">CONTACT US</a>\n",
    "            </nav>\n",
    "            <section id=\"content\">\n",
    "                <h1>The Ironhack Breakfast Place</h1>\n",
    "                <p>Here you will find all sorts of delicious treats</p>\n",
    "                <figure>\n",
    "                    <img alt=\"healthy breakfast\" src=\"breakfast.jpg\" width=\"400\"/>\n",
    "                    <figcaption>CC Image courtesy of Ruth Hartnup on Flickr</figcaption>\n",
    "                </figure>\n",
    "            </section>\n",
    "            <footer>\n",
    "                <p class=\"love\">Made with love by Ironhack</p>\n",
    "            </footer>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "This is the Source Code of the link above. What do we see here? We see structured code with each element being located in specific order. Let's go step by step.\n",
    "1. \n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "```\n",
    "HTML pages can be written in different syntax models. The most common one is HTML. Second most populat is XML.\n",
    "2. ```html\n",
    "<html>\n",
    "    ...\n",
    "</html>\n",
    "```\n",
    "Defines the webpage. Everything inside is the body of your page.\n",
    "3. ```html\n",
    "<head>\n",
    "    ...\n",
    "</head>\n",
    "```\n",
    "Defines the header. This part is invisible on the page. Here you define meta data of webpage, keywords, styling, etc.\n",
    "4. ```html\n",
    "<body>\n",
    "    ...\n",
    "</body>\n",
    "```\n",
    "Defines the webpage itself. Everything defined here will be visible for end user. \n",
    "5. ```html\n",
    "<div>\n",
    "    ...\n",
    "</div>\n",
    "```\n",
    "Block (container) element. Can be located, sized, parametrized on the page. Every element inside will follow rules defined in `div` block.\n",
    "6. ```html\n",
    "<a href='some link'>\n",
    "    ...\n",
    "</a>\n",
    "```\n",
    "Hyperlink. Has `href` attribute that indicates the target of hyperlink.\n",
    "7. ```html\n",
    "<h*>\n",
    "    ...\n",
    "</h*>\n",
    "```\n",
    "Header. Starts from `h1`, which indicates the biggest font size and top header, goes all the way to `h6` which is the smallest header.\n",
    "8. ```html\n",
    "<p>\n",
    "    ...\n",
    "</p>\n",
    "```\n",
    "Plaintext. \n",
    "9. ```html\n",
    "<img src='some link'>\n",
    "    ...\n",
    "</img>\n",
    "```\n",
    "Image. Has `src` attribute that indicates the location of image. Width and Heigth can be indicated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In terms of `css`, we can see that some of the tags have `id` and `class` being specified. \n",
    "\n",
    "`id` attribute is a unique identifier of a tag. Usually is applied for very specific pieces of webpage that is updated frequently. `class` attribute is a styling attribute. Tags with the same styling are objects of the same class family. So, if you need to identically format 20 objects on a page you just specify their class to be the same.\n",
    "\n",
    "For web scrappers, those two attributes are core anchors to detect correct piece of information.  \n",
    "Please, find [here](https://flukeout.github.io) a tutorial on `css` selectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Requests Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests as r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`requests` library allows us to send requests to any webpage. It provides full control over requests we send, allowing us change proxies, IP-addresses, specifying headers, payloads, etc. Two words: perfect scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1=r.get('https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/the-html5-breakfast-site.html')\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`get` method allows us send a `GET` request to the webpage. Response is stored in the r1 object of `requests.models.Response` class. As we can see, class displays the status code of the page when the object is printed.\n",
    "\n",
    "[Here](https://www.restapitutorial.com/httpstatuscodes.html) you can find full list of status codes you can receive from a webpage. Most important are following:\n",
    "* 1xx - Informational. You won't receive this code while scrapping.\n",
    "* 2xx - OK. Request was sent correctly and server responded correctly.\n",
    "* 3xx - Redirect.\n",
    "* 4xx - Request was sent incorrectly / You are blocked / Page doesn't exist\n",
    "* 5xx - Request was sent correclty, but server can't responde. \n",
    "\n",
    "As you can deduce, 200 is the only accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2=r.get('https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/forbidden')\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sometimes you will receive a bad 403 response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r3=r.get('http://google.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We all know that few years ago almost all the websites on Internet switched from `http` to `https` protocol. What if I try to access `http` webpage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I receive a 200 status code. Which is cool. But..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Response [301]>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In `history` attribute of response object I can see the history of all redirections. So, since `http` is not in use anymore, webpage automatically redirects us to `https` based webpage. We can see it in history - the first link received 301 status code, which is redirect.\n",
    "\n",
    "Similarly, if I go to `http://fb.com` I will be redirected. Twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Response [302]>, <Response [301]>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3=r.get('http://fb.com')\n",
    "r3.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r1.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Keeping in mind that we always want to automize processes, let's define a function with basic error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    response=r.get(url)\n",
    "    if response.status_code==200:\n",
    "        print('alles gut')\n",
    "    elif response.status_code>400:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alles gut\n"
     ]
    }
   ],
   "source": [
    "get_data('http://fb.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    }
   ],
   "source": [
    "get_data('https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/forbidden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Seems to be nice, right? In fact, `requests` library already simplified the whole process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    response=r.get(url)\n",
    "    if response:\n",
    "        print('alles gut')\n",
    "    else:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alles gut\n"
     ]
    }
   ],
   "source": [
    "get_data('http://fb.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    }
   ],
   "source": [
    "get_data('https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/forbidden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you use a Response instance in a conditional expression, it will evaluate to `True` if the status code was between 200 and 400, and `False` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get our first useful data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect some data from Allociné. There is a new article about Batman: \"*15 ans de Batman Begins : comment Christopher Nolan a sauvé l'Homme Chauve-Souris*\".\n",
    "\n",
    "Most of the webpages are loaded using `GET` request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "responce=r.get('http://www.allocine.fr/article/fichearticle_gen_carticle=18690706.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<HTML><HEAD>\\n<TITLE>Access Denied</TITLE>\\n</HEAD><BODY>\\n<H1>Access Denied</H1>\\n \\nYou don\\'t have permission to access \"http&#58;&#47;&#47;www&#46;france24&#46;com&#47;fr&#47;20200617&#45;hidalgo&#45;dati&#45;buzyn&#45;trois&#45;candidates&#45;pour&#45;paris&#45;trois&#45;strat&#37;C3&#37;A9gies\" on this server.<P>\\nReference&#32;&#35;18&#46;2df31402&#46;1592390642&#46;1e12d267\\n</BODY>\\n</HTML>\\n'\n"
     ]
    }
   ],
   "source": [
    "response = r.get('https://www.france24.com/fr/20200617-hidalgo-dati-buzyn-trois-candidates-pour-paris-trois-stratégies')\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
